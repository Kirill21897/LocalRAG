{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bc6b5a",
   "metadata": {},
   "source": [
    "# Тестирование функций и методов\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3528b",
   "metadata": {},
   "source": [
    "### Модуль Ingestion (Docling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88779b9c",
   "metadata": {},
   "source": [
    "#### Загрузка и конвертация документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "742e665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[INFO] 2026-01-23 16:38:50,979 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:38:50,992 [RapidOCR] device_config.py:50: Using CPU device\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:38:50,995 [RapidOCR] download_file.py:68: Initiating download: https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.5.0/torch/PP-OCRv4/det/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:38:52,711 [RapidOCR] download_file.py:82: Download size: 13.83MB\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:23,731 [RapidOCR] download_file.py:95: Successfully saved to: D:\\Projects\\LocalRAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:23,732 [RapidOCR] main.py:50: Using D:\\Projects\\LocalRAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:23,923 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:23,924 [RapidOCR] device_config.py:50: Using CPU device\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:23,926 [RapidOCR] download_file.py:68: Initiating download: https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.5.0/torch/PP-OCRv4/cls/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:26,850 [RapidOCR] download_file.py:82: Download size: 0.56MB\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:27,652 [RapidOCR] download_file.py:95: Successfully saved to: D:\\Projects\\LocalRAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:27,654 [RapidOCR] main.py:50: Using D:\\Projects\\LocalRAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:27,728 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:27,729 [RapidOCR] device_config.py:50: Using CPU device\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:27,730 [RapidOCR] download_file.py:68: Initiating download: https://www.modelscope.cn/models/RapidAI/RapidOCR/resolve/v3.5.0/torch/PP-OCRv4/rec/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:39:29,959 [RapidOCR] download_file.py:82: Download size: 25.67MB\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:40:19,648 [RapidOCR] download_file.py:95: Successfully saved to: D:\\Projects\\LocalRAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-23 16:40:19,651 [RapidOCR] main.py:50: Using D:\\Projects\\LocalRAG\\.venv\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "RapidOCR returned empty result!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved intermediate file: data\\processed\\sample.md\n",
      "Result_doc: ## ФГОБУ ВПО ПГУТИ кафедра ТОРС\n",
      "\n",
      "## Методическая разработка\n",
      "\n",
      "к лабораторным работам по курсу\n",
      "\n",
      "## Осн...\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import src.document_loader as document_loader\n",
    "import config.config as cfg\n",
    "\n",
    "def test_load_document():\n",
    "    file_path = str(cfg.RAW_DATA_DIR / \"sample.pdf\")\n",
    "    result = document_loader.load_document(file_path)\n",
    "    print(f\"Result_doc: {result[0:100]}...\")  # Print first 100 characters for brevity\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_load_document()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f7c69",
   "metadata": {},
   "source": [
    "#### Чанкирование по кол-ву симовлов с перекрытием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d48ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл 'sample.md' успешно разбит.\n",
      "Количество чанков: 12\n",
      "Пример первого чанка:\n",
      "'1. Научные открытия и технологические прорывы\\n\\nВ 2023 году учёные из ЦЕРНа подтвердили существование'...\n"
     ]
    }
   ],
   "source": [
    "from src.chunker import chunk_text\n",
    "from config.config import PROCESSED_DATA_DIR\n",
    "\n",
    "file_path = PROCESSED_DATA_DIR / \"sample.md\"\n",
    "markdown_content = file_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "CHUNK_SIZE = 500 \n",
    "OVERLAP = 100\n",
    "file_name = file_path.name # Сохраняем имя для Qdrant\n",
    "\n",
    "chunks = chunk_text(markdown_content, chunk_size=CHUNK_SIZE, overlap=OVERLAP)\n",
    "\n",
    "print(f\"Файл '{file_name}' успешно разбит.\")\n",
    "print(f\"Количество чанков: {len(chunks)}\")\n",
    "print(f\"Пример первого чанка:\\n{repr(chunks[0][:100])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ec59d",
   "metadata": {},
   "source": [
    "#### Сохранение векторизованных данных в Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb057789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LocalRAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация векторов для 12 чанков...\n",
      "Данные успешно загружены в коллекцию 'docs_collection'\n"
     ]
    }
   ],
   "source": [
    "from src.embedder import vectorize_and_upload\n",
    "\n",
    "q_client, embed_model = vectorize_and_upload(chunks, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384e948",
   "metadata": {},
   "source": [
    "### Модули Retrieval и Reranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424063d",
   "metadata": {},
   "source": [
    "#### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "756d415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 3 кандидатов через векторный поиск.\n"
     ]
    }
   ],
   "source": [
    "from src.retrieval import retrieve\n",
    "\n",
    "user_query = \"Скольки градусам может достичь потепление к 2050 году?\"\n",
    "candidates = retrieve(user_query, q_client, embed_model, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db76377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-3 кандидата по запросу:\n",
      "1. {'text': 'аду МГЭИК (Межправительственной группы экспертов по изменению климата) за 2022 год, глобальная средняя температура уже на 1,15°C выше доиндустриального уровня. Если выбросы парниковых газов не будут радикально сокращены, к 2050 году потепление может достичь 2,7°C, что приведёт к катастрофическим последствиям: повышению уровня моря, экстремальным погодным явлениям и массовому вымиранию видов.\\n\\nОднако существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утвержд', 'score': 0.7725014352780308, 'metadata': {'source': 'sample.md', 'chunk_id': 5}}\n",
      "\n",
      "2. {'text': 'ко существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утверждают, что адаптация к изменениям климата может быть более эффективной стратегией, чем полный отказ от ископаемого топлива. Тем не менее, большинство научного сообщества поддерживает Парижское соглашение 2015 года, целью которого является удержание роста температуры ниже 2°C.\\n\\n## 4. Искусственный интеллект и этика\\n\\nС развитием больших языковых моделей (LLM), таких как GPT-4, Llama 3 и Claude 3, возн', 'score': 0.5040614310777544, 'metadata': {'source': 'sample.md', 'chunk_id': 6}}\n",
      "\n",
      "3. {'text': ' содержащих стереотипы, она может их воспроизводить.\\n\\nВ то же время ИИ активно применяется в медицине: алгоритмы DeepMind (подразделение Google) помогают диагностировать диабетическую ретинопатию и рак молочной железы с точностью, сопоставимой с экспертами-людьми.\\n\\n## 5. География и демография\\n\\nНаселение Земли достигло 8 миллиардов человек в ноябре 2022 года. По прогнозам ООН, пик будет достигнут около 2086 года - на уровне 10,4 миллиарда. При этом старение населения становится серьёзной проблем', 'score': 0.3601881203512009, 'metadata': {'source': 'sample.md', 'chunk_id': 8}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Топ-3 кандидата по запросу:\")\n",
    "for i, candidate in enumerate(candidates, start=1):\n",
    "    print(f\"{i}. {candidate}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1950a",
   "metadata": {},
   "source": [
    "#### Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12638658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "\n",
      "--- Релевантный чанк №1 (Score: 8.6397) ---\n",
      "аду МГЭИК (Межправительственной группы экспертов по изменению климата) за 2022 год, глобальная средняя температура уже на 1,15°C выше доиндустриального уровня. Если выбросы парниковых газов не будут р...\n",
      "\n",
      "--- Релевантный чанк №2 (Score: 8.4987) ---\n",
      " содержащих стереотипы, она может их воспроизводить.\n",
      "\n",
      "В то же время ИИ активно применяется в медицине: алгоритмы DeepMind (подразделение Google) помогают диагностировать диабетическую ретинопатию и ра...\n",
      "\n",
      "--- Релевантный чанк №3 (Score: 7.9926) ---\n",
      "ко существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утверждают, что адаптация к изменениям климата может быть более эффективной стратегией, чем полный отказ от...\n"
     ]
    }
   ],
   "source": [
    "from src.reranker import rerank\n",
    "\n",
    "final_context = rerank(user_query, candidates, top_n=3)\n",
    "\n",
    "# Вывод результата\n",
    "for i, res in enumerate(final_context):\n",
    "    print(f\"\\n--- Релевантный чанк №{i+1} (Score: {res['rerank_score']:.4f}) ---\")\n",
    "    print(res[\"text\"][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f20977c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'аду МГЭИК (Межправительственной группы экспертов по изменению климата) за 2022 год, глобальная средняя температура уже на 1,15°C выше доиндустриального уровня. Если выбросы парниковых газов не будут радикально сокращены, к 2050 году потепление может достичь 2,7°C, что приведёт к катастрофическим последствиям: повышению уровня моря, экстремальным погодным явлениям и массовому вымиранию видов.\\n\\nОднако существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утвержд'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_context[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f76b69",
   "metadata": {},
   "source": [
    "### Модуль Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddfdfcb",
   "metadata": {},
   "source": [
    "#### Генератор с использованием локальной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02169b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сгенерированный ответ ---\n",
      "К 2050 году потепление может достичь **2,7°C**, если выбросы парниковых газов не будут радикально сокращены.\n"
     ]
    }
   ],
   "source": [
    "from src.generator import Generator\n",
    "\n",
    "generator = Generator()\n",
    "\n",
    "user_query = \"Скольки градусам может достичь потепление к 2050 году?\"\n",
    "response = generator.generate(user_query, final_context[0][\"text\"])\n",
    "\n",
    "print(\"\\n--- Сгенерированный ответ ---\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c196d20",
   "metadata": {},
   "source": [
    "Получение итогового списка контекста модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d4f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_context_text = []\n",
    "for i in range(len(final_context)):\n",
    "    final_context_text.append(final_context[i][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e9c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['аду МГЭИК (Межправительственной группы экспертов по изменению климата) за 2022 год, глобальная средняя температура уже на 1,15°C выше доиндустриального уровня. Если выбросы парниковых газов не будут радикально сокращены, к 2050 году потепление может достичь 2,7°C, что приведёт к катастрофическим последствиям: повышению уровня моря, экстремальным погодным явлениям и массовому вымиранию видов.\\n\\nОднако существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утвержд', ' содержащих стереотипы, она может их воспроизводить.\\n\\nВ то же время ИИ активно применяется в медицине: алгоритмы DeepMind (подразделение Google) помогают диагностировать диабетическую ретинопатию и рак молочной железы с точностью, сопоставимой с экспертами-людьми.\\n\\n## 5. География и демография\\n\\nНаселение Земли достигло 8 миллиардов человек в ноябре 2022 года. По прогнозам ООН, пик будет достигнут около 2086 года - на уровне 10,4 миллиарда. При этом старение населения становится серьёзной проблем', 'ко существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утверждают, что адаптация к изменениям климата может быть более эффективной стратегией, чем полный отказ от ископаемого топлива. Тем не менее, большинство научного сообщества поддерживает Парижское соглашение 2015 года, целью которого является удержание роста температуры ниже 2°C.\\n\\n## 4. Искусственный интеллект и этика\\n\\nС развитием больших языковых моделей (LLM), таких как GPT-4, Llama 3 и Claude 3, возн']\n"
     ]
    }
   ],
   "source": [
    "print(final_context_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52a094",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation (Ragas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c3c57",
   "metadata": {},
   "source": [
    "#### Полный цикл оценки (Full Pipeline Evaluation)\n",
    "Включает в себя подготовку данных, генерацию ответов и расчет метрик: Faithfulness, Answer Relevancy, Context Precision, Context Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c892886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LocalRAG\\src\\evaluation\\ragas_eval.py:32: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings = HuggingFaceEmbeddings(model_name=cfg.EMBEDDING_MODEL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ragas Evaluator initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation.ragas_eval import RagasEvaluator\n",
    "\n",
    "# Инициализация Ragas Evaluator\n",
    "evaluator = RagasEvaluator()\n",
    "print(\"Ragas Evaluator initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70cbc6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск генерации ответов...\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Q: Скольки градусам может достичь потепление к 2050 году?\n",
      "A: К 2050 году, если выбросы парниковых газов не будут радикально сокращены, потепление может достичь *...\n",
      "\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Q: Какие алгоритмы DeepMind используются в медицине?\n",
      "A: Алгоритмы DeepMind, упомянутые в контексте, применяются в медицине для диагностики диабетической рет...\n",
      "\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Q: Каков прогноз численности населения Земли на 2086 год?\n",
      "A: Прогноз численности населения Земли на 2086 год, согласно контексту, составляет **10,4 миллиарда чел...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Подготовка тестовых данных (Questions & Ground Truths)\n",
    "test_questions = [\n",
    "    \"Скольки градусам может достичь потепление к 2050 году?\",\n",
    "    \"Какие алгоритмы DeepMind используются в медицине?\",\n",
    "    \"Каков прогноз численности населения Земли на 2086 год?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"Потепление может достичь 2,7°C.\",\n",
    "    \"Алгоритмы DeepMind помогают диагностировать диабетическую ретинопатию и рак молочной железы.\",\n",
    "    \"По прогнозам ООН, пик будет достигнут около 2086 года на уровне 10,4 миллиарда человек.\"\n",
    "]\n",
    "\n",
    "# 2. Запуск пайплайна (Inference)\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "print(\"Запуск генерации ответов...\")\n",
    "for q in test_questions:\n",
    "    # Retrieve\n",
    "    candidates = retrieve(q, q_client, embed_model, top_k=5)\n",
    "    final_c = rerank(q, candidates, top_n=3)\n",
    "    \n",
    "    # Extract context texts\n",
    "    c_texts = [c[\"text\"] for c in final_c]\n",
    "    combined_c = \"\\n\\n\".join(c_texts)\n",
    "    \n",
    "    # Generate\n",
    "    resp = generator.generate(q, combined_c)\n",
    "    \n",
    "    answers.append(resp)\n",
    "    contexts.append(c_texts)\n",
    "    print(f\"Q: {q}\\nA: {resp[:100]}...\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74be77e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск оценки Ragas через модуль src.evaluation...\n",
      "Starting Ragas evaluation pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   8%|▊         | 1/12 [00:41<07:31, 41.07s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  42%|████▏     | 5/12 [02:08<03:06, 26.63s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:  75%|███████▌  | 9/12 [04:23<01:50, 36.67s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 12/12 [05:17<00:00, 26.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты оценки:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Скольки градусам может достичь потепление к 20...</td>\n",
       "      <td>[аду МГЭИК (Межправительственной группы экспер...</td>\n",
       "      <td>К 2050 году, если выбросы парниковых газов не ...</td>\n",
       "      <td>Потепление может достичь 2,7°C.</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Какие алгоритмы DeepMind используются в медицине?</td>\n",
       "      <td>[ содержащих стереотипы, она может их воспроиз...</td>\n",
       "      <td>Алгоритмы DeepMind, упомянутые в контексте, пр...</td>\n",
       "      <td>Алгоритмы DeepMind помогают диагностировать ди...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Каков прогноз численности населения Земли на 2...</td>\n",
       "      <td>[аду МГЭИК (Межправительственной группы экспер...</td>\n",
       "      <td>Прогноз численности населения Земли на 2086 го...</td>\n",
       "      <td>По прогнозам ООН, пик будет достигнут около 20...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.999443</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Скольки градусам может достичь потепление к 20...   \n",
       "1  Какие алгоритмы DeepMind используются в медицине?   \n",
       "2  Каков прогноз численности населения Земли на 2...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [аду МГЭИК (Межправительственной группы экспер...   \n",
       "1  [ содержащих стереотипы, она может их воспроиз...   \n",
       "2  [аду МГЭИК (Межправительственной группы экспер...   \n",
       "\n",
       "                                            response  \\\n",
       "0  К 2050 году, если выбросы парниковых газов не ...   \n",
       "1  Алгоритмы DeepMind, упомянутые в контексте, пр...   \n",
       "2  Прогноз численности населения Земли на 2086 го...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0                    Потепление может достичь 2,7°C.      1.000000   \n",
       "1  Алгоритмы DeepMind помогают диагностировать ди...      1.000000   \n",
       "2  По прогнозам ООН, пик будет достигнут около 20...      0.666667   \n",
       "\n",
       "   answer_relevancy  context_precision  context_recall  \n",
       "0          0.862986           1.000000             1.0  \n",
       "1          0.702630           1.000000             1.0  \n",
       "2          0.999443           0.333333             1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to data/evaluation_results/evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "# 4. Запуск оценки\n",
    "print(\"Запуск оценки Ragas через модуль src.evaluation...\")\n",
    "df_results = evaluator.run_evaluation(\n",
    "    questions=test_questions,\n",
    "    answers=answers,\n",
    "    contexts=contexts,\n",
    "    ground_truths=ground_truths\n",
    ")\n",
    "\n",
    "print(\"\\nРезультаты оценки:\")\n",
    "display(df_results)\n",
    "\n",
    "# Сохранение результатов\n",
    "evaluator.save_results(df_results, \"data/evaluation_results/evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e71380f",
   "metadata": {},
   "source": [
    "## Сравнительное тестирование методов чанкирования\n",
    "---\n",
    "В этом разделе мы запускаем полный цикл RAG (Ingestion -> Chunking -> Embedding -> Retrieval -> Reranking -> Generation -> Evaluation) для каждого из 5 реализованных методов чанкирования, чтобы сравнить их эффективность.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a33249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LocalRAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст загружен, длина: 25225 символов\n",
      "Loading shared embedding model (Ollama): nomic-embed-text...\n",
      "Компоненты инициализированы.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LocalRAG\\src\\evaluation\\ragas_eval.py:29: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import ChatOllama``.\n",
      "  self.llm = ChatOllama(\n",
      "d:\\Projects\\LocalRAG\\src\\model_cache.py:17: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaEmbeddings``.\n",
      "  self.client = OllamaEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Импорты необходимых модулей\n",
    "import pandas as pd\n",
    "from src.chunkers.recursive_chunker import chunk_recursive\n",
    "from src.chunkers.token_chunker import chunk_token\n",
    "from src.chunkers.markdown_chunker import chunk_markdown\n",
    "from src.chunkers.sentence_window_chunker import chunk_sentence_window\n",
    "from src.chunkers.semantic_chunker import chunk_semantic\n",
    "\n",
    "from src.embedder import vectorize_and_upload\n",
    "from src.retrieval import retrieve\n",
    "from src.reranker import rerank\n",
    "from src.generator import Generator\n",
    "import importlib\n",
    "import src.evaluation.ragas_eval\n",
    "import src.model_cache\n",
    "importlib.reload(src.model_cache)\n",
    "importlib.reload(src.evaluation.ragas_eval)\n",
    "from src.evaluation.ragas_eval import RagasEvaluator\n",
    "from config.config import PROCESSED_DATA_DIR\n",
    "\n",
    "# Загрузка текста\n",
    "file_path = PROCESSED_DATA_DIR / \"sample.md\"\n",
    "markdown_content = file_path.read_text(encoding=\"utf-8\")\n",
    "print(f\"Текст загружен, длина: {len(markdown_content)} символов\")\n",
    "\n",
    "# Инициализация общих компонентов\n",
    "generator = Generator()\n",
    "evaluator = RagasEvaluator()\n",
    "print(\"Компоненты инициализированы.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37015c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовые данные (Вопросы и эталонные ответы)\n",
    "test_questions = [\n",
    "    \"Как называется инструмент визуального моделирования в среде Scilab?\",\n",
    "    \"Когда срабатывает блок, имеющий управляющий вход?\",\n",
    "    \"Какую функцию выполняет блок ENDBLK?\",\n",
    "    #\"Что означает отрицательное значение в векторе Drawing colors осциллографа?\",\n",
    "    #\"Какое условие накладывается на параметр Buffer size блока TIME_DELAY?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"Инструмент называется Xcos.\",\n",
    "    \"Каждый раз при поступлении на него сигнала активации.\",\n",
    "    \"Задаёт конечное время моделирования.\",\n",
    "    #\"На графике вместо непрерывных кривых будут отображаться метки.\",\n",
    "    #\"Размер буфера должен быть не меньше числа отсчётов сигнала за время задержки.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf153f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_for_method(method_name, chunk_func, text, questions, ground_truths):\n",
    "    print(f\"\\n{'='*20} Testing Method: {method_name} {'='*20}\")\n",
    "    \n",
    "    # 1. Chunking\n",
    "    print(\"1. Chunking...\")\n",
    "    try:\n",
    "        # Некоторые методы могут требовать доп. параметров, но мы используем дефолтные для теста\n",
    "        chunks = chunk_func(text)\n",
    "        print(f\"   Получено {len(chunks)} чанков.\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Ошибка при чанкировании: {e}\")\n",
    "        return None\n",
    "        \n",
    "    if not chunks:\n",
    "        print(\"   Чанки не созданы.\")\n",
    "        return None\n",
    "\n",
    "    # 2. Embedding & Upload (Unique Collection)\n",
    "    collection_name = f\"docs_{method_name.lower().replace(' ', '_')}\"\n",
    "    print(f\"2. Embedding to collection '{collection_name}'...\")\n",
    "    client, embed_model = vectorize_and_upload(chunks, \"sample.md\", collection_name=collection_name)\n",
    "\n",
    "    # 3. Retrieval, Reranking, Generation\n",
    "    print(\"3. Running RAG Pipeline (Retrieve -> Rerank -> Generate)...\")\n",
    "    answers = []\n",
    "    contexts = []\n",
    "    \n",
    "    for q in questions:\n",
    "        # Retrieve\n",
    "        candidates = retrieve(q, client, embed_model, top_k=5, collection_name=collection_name)\n",
    "        # Rerank\n",
    "        final_c = rerank(q, candidates, top_n=3)\n",
    "        \n",
    "        # Extract context texts\n",
    "        c_texts = [c[\"text\"] for c in final_c]\n",
    "        combined_c = \"\\n\\n\".join(c_texts)\n",
    "        \n",
    "        # Generate\n",
    "        resp = generator.generate(q, combined_c)\n",
    "        answers.append(resp)\n",
    "        contexts.append(c_texts)\n",
    "        # print(f\"   Q: {q[:30]}... -> A: {resp[:30]}...\")\n",
    "\n",
    "    # 4. Evaluation\n",
    "    print(\"4. Evaluating...\")\n",
    "    df_results = evaluator.run_evaluation(\n",
    "        questions=questions,\n",
    "        answers=answers,\n",
    "        contexts=contexts,\n",
    "        ground_truths=ground_truths\n",
    "    )\n",
    "    \n",
    "    # Add method column\n",
    "    df_results['method'] = method_name\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de6c1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запуск тестирования с 1 повторениями для каждого метода...\n",
      "\n",
      "\n",
      "##############################\n",
      ">>> Run 1/1 for Method: Recursive\n",
      "##############################\n",
      "\n",
      "==================== Testing Method: Recursive ====================\n",
      "1. Chunking...\n",
      "   Получено 32 чанков.\n",
      "2. Embedding to collection 'docs_recursive'...\n",
      "Генерация векторов для 32 чанков...\n",
      "Данные успешно загружены в коллекцию 'docs_recursive'\n",
      "3. Running RAG Pipeline (Retrieve -> Rerank -> Generate)...\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "4. Evaluating...\n",
      "Starting Ragas evaluation pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [09:40<00:00, 48.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################\n",
      ">>> Run 1/1 for Method: Token\n",
      "##############################\n",
      "\n",
      "==================== Testing Method: Token ====================\n",
      "1. Chunking...\n",
      "   Получено 24 чанков.\n",
      "2. Embedding to collection 'docs_token'...\n",
      "Генерация векторов для 24 чанков...\n",
      "Данные успешно загружены в коллекцию 'docs_token'\n",
      "3. Running RAG Pipeline (Retrieve -> Rerank -> Generate)...\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "4. Evaluating...\n",
      "Starting Ragas evaluation pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [07:58<00:00, 39.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################\n",
      ">>> Run 1/1 for Method: Markdown\n",
      "##############################\n",
      "\n",
      "==================== Testing Method: Markdown ====================\n",
      "1. Chunking...\n",
      "   Получено 43 чанков.\n",
      "2. Embedding to collection 'docs_markdown'...\n",
      "Генерация векторов для 43 чанков...\n",
      "Данные успешно загружены в коллекцию 'docs_markdown'\n",
      "3. Running RAG Pipeline (Retrieve -> Rerank -> Generate)...\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "4. Evaluating...\n",
      "Starting Ragas evaluation pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [06:35<00:00, 32.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################\n",
      ">>> Run 1/1 for Method: Sentence Window\n",
      "##############################\n",
      "\n",
      "==================== Testing Method: Sentence Window ====================\n",
      "1. Chunking...\n",
      "   Получено 283 чанков.\n",
      "2. Embedding to collection 'docs_sentence_window'...\n",
      "Генерация векторов для 283 чанков...\n",
      "Данные успешно загружены в коллекцию 'docs_sentence_window'\n",
      "3. Running RAG Pipeline (Retrieve -> Rerank -> Generate)...\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "4. Evaluating...\n",
      "Starting Ragas evaluation pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [06:06<00:00, 30.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################\n",
      ">>> Run 1/1 for Method: Semantic\n",
      "##############################\n",
      "\n",
      "==================== Testing Method: Semantic ====================\n",
      "1. Chunking...\n",
      "   Получено 5 чанков.\n",
      "2. Embedding to collection 'docs_semantic'...\n",
      "Генерация векторов для 5 чанков...\n",
      "Данные успешно загружены в коллекцию 'docs_semantic'\n",
      "3. Running RAG Pipeline (Retrieve -> Rerank -> Generate)...\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "Найдено 5 кандидатов через векторный поиск.\n",
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "4. Evaluating...\n",
      "Starting Ragas evaluation pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 12/12 [09:13<00:00, 46.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Все тесты завершены. Переходим к анализу.\n"
     ]
    }
   ],
   "source": [
    "# Список методов для тестирования\n",
    "methods = [\n",
    "    (\"Recursive\", chunk_recursive),\n",
    "    (\"Token\", chunk_token),\n",
    "    (\"Markdown\", chunk_markdown),\n",
    "    (\"Sentence Window\", chunk_sentence_window),\n",
    "    (\"Semantic\", chunk_semantic)\n",
    "]\n",
    "\n",
    "NUM_RUNS = 1\n",
    "all_results = []\n",
    "\n",
    "import time\n",
    "print(f\"Запуск тестирования с {NUM_RUNS} повторениями для каждого метода...\\n\")\n",
    "\n",
    "for name, func in methods:\n",
    "    for run_i in range(1, NUM_RUNS + 1):\n",
    "        print(f\"\\n{'#'*30}\")\n",
    "        print(f\">>> Run {run_i}/{NUM_RUNS} for Method: {name}\")\n",
    "        print(f\"{'#'*30}\")\n",
    "        \n",
    "        try:\n",
    "            df = run_pipeline_for_method(name, func, markdown_content, test_questions, ground_truths)\n",
    "            if df is not None:\n",
    "                df['run_id'] = run_i  # Add run identifier\n",
    "                all_results.append(df)\n",
    "            else:\n",
    "                print(f\"Warning: No results returned for {name} run {run_i}\")\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL ERROR in {name} run {run_i}: {e}\")\n",
    "            print(\"Skipping this run and continuing...\")\n",
    "            time.sleep(5)\n",
    "\n",
    "# Объединение результатов\n",
    "if all_results:\n",
    "    final_df = pd.concat(all_results, ignore_index=True)\n",
    "    print(\"\\nВсе тесты завершены. Переходим к анализу.\")\n",
    "else:\n",
    "    print(\"\\nНет результатов. Проверьте ошибки выше.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c93582a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сводная таблица (средние значения по 3 запускам):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Markdown</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.694965</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.523148</td>\n",
       "      <td>0.508017</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Semantic</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.629056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence Window</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.601956</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Token</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.578815</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            method  faithfulness  answer_relevancy  context_precision  \\\n",
       "0         Markdown      0.933333          0.694965           0.888889   \n",
       "1        Recursive      0.523148          0.508017           0.638889   \n",
       "2         Semantic      0.407407          0.629056           1.000000   \n",
       "3  Sentence Window      0.944444          0.601956           0.750000   \n",
       "4            Token      0.583333          0.578815           0.388889   \n",
       "\n",
       "   context_recall  \n",
       "0        1.000000  \n",
       "1        1.000000  \n",
       "2        1.000000  \n",
       "3        1.000000  \n",
       "4        0.666667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты сохранены в csv.\n"
     ]
    }
   ],
   "source": [
    "if all_results:\n",
    "    # Группировка по методу и вычисление среднего по всем запускам\n",
    "    numeric_cols = ['faithfulness', 'answer_relevancy', 'context_precision', 'context_recall']\n",
    "    summary = final_df.groupby('method')[numeric_cols].mean().reset_index()\n",
    "    \n",
    "    print(\"Сводная таблица (средние значения по 3 запускам):\")\n",
    "    display(summary)\n",
    "    \n",
    "    # Сохранение полных результатов\n",
    "    final_df.to_csv(\"data/evaluation_results/chunking_comparison_full.csv\", index=False)\n",
    "    summary.to_csv(\"data/evaluation_results/chunking_comparison_summary.csv\", index=False)\n",
    "    print(\"\\nРезультаты сохранены в csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045d2f67",
   "metadata": {},
   "source": [
    "### Автоматический анализ результатов\n",
    "Ниже генерируется текстовый отчет на основе полученных метрик.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f756ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Отчет по сравнению методов чанкирования\n",
      "\n",
      "## Лучшие методы по метрикам:\n",
      "- **faithfulness**: Sentence Window (0.9444)\n",
      "- **answer_relevancy**: Markdown (0.6950)\n",
      "- **context_precision**: Semantic (1.0000)\n",
      "- **context_recall**: Markdown (1.0000)\n",
      "\n",
      "## Общий вывод:\n",
      "На основе усредненного показателя (Composite Score) лучшим методом является **Markdown** со счетом **0.8793**.\n",
      "\n",
      "## Детальный разбор:\n",
      "### Markdown\n",
      "* Средний балл: 0.8793\n",
      "* Сильные стороны: faithfulness, answer_relevancy, context_precision, context_recall\n",
      "* Слабые стороны: \n",
      "\n",
      "### Sentence Window\n",
      "* Средний балл: 0.8241\n",
      "* Сильные стороны: faithfulness, context_precision, context_recall\n",
      "* Слабые стороны: answer_relevancy\n",
      "\n",
      "### Semantic\n",
      "* Средний балл: 0.7591\n",
      "* Сильные стороны: answer_relevancy, context_precision, context_recall\n",
      "* Слабые стороны: faithfulness\n",
      "\n",
      "### Recursive\n",
      "* Средний балл: 0.6675\n",
      "* Сильные стороны: context_recall\n",
      "* Слабые стороны: faithfulness, answer_relevancy, context_precision\n",
      "\n",
      "### Token\n",
      "* Средний балл: 0.5544\n",
      "* Сильные стороны: \n",
      "* Слабые стороны: faithfulness, answer_relevancy, context_precision, context_recall\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_report(summary_df):\n",
    "    report = []\n",
    "    report.append(\"# Отчет по сравнению методов чанкирования\\n\")\n",
    "    \n",
    "    # 1. Best Method per Metric\n",
    "    report.append(\"## Лучшие методы по метрикам:\")\n",
    "    metrics = ['faithfulness', 'answer_relevancy', 'context_precision', 'context_recall']\n",
    "    \n",
    "    scores = {}\n",
    "    for _, row in summary_df.iterrows():\n",
    "        scores[row['method']] = 0\n",
    "        \n",
    "    for metric in metrics:\n",
    "        best_row = summary_df.loc[summary_df[metric].idxmax()]\n",
    "        report.append(f\"- **{metric}**: {best_row['method']} ({best_row[metric]:.4f})\")\n",
    "        scores[best_row['method']] += 1\n",
    "    \n",
    "    # 2. Overall Winner\n",
    "    report.append(\"\\n## Общий вывод:\")\n",
    "    # Calculate composite score (simple average of 4 metrics)\n",
    "    summary_df['composite_score'] = summary_df[metrics].mean(axis=1)\n",
    "    winner = summary_df.loc[summary_df['composite_score'].idxmax()]\n",
    "    \n",
    "    report.append(f\"На основе усредненного показателя (Composite Score) лучшим методом является **{winner['method']}** со счетом **{winner['composite_score']:.4f}**.\")\n",
    "    \n",
    "    # 3. Detailed Breakdown\n",
    "    report.append(\"\\n## Детальный разбор:\")\n",
    "    for _, row in summary_df.sort_values('composite_score', ascending=False).iterrows():\n",
    "        report.append(f\"### {row['method']}\")\n",
    "        report.append(f\"* Средний балл: {row['composite_score']:.4f}\")\n",
    "        report.append(f\"* Сильные стороны: {', '.join([m for m in metrics if row[m] >= summary_df[m].mean()])}\")\n",
    "        report.append(f\"* Слабые стороны: {', '.join([m for m in metrics if row[m] < summary_df[m].mean()])}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "if all_results:\n",
    "    analysis_text = generate_report(summary)\n",
    "    print(analysis_text)\n",
    "    \n",
    "    # Save report\n",
    "    with open(\"data/evaluation_results/analysis_report.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(analysis_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
