{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bc6b5a",
   "metadata": {},
   "source": [
    "# Тестирование функций и методов\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3528b",
   "metadata": {},
   "source": [
    "### Модуль Ingestion (Docling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88779b9c",
   "metadata": {},
   "source": [
    "#### Загрузка и конвертация документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742e665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:23,816 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:23,824 [RapidOCR] device_config.py:50: Using CPU device\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:23,836 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:23,837 [RapidOCR] main.py:50: Using D:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:24,133 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:24,134 [RapidOCR] device_config.py:50: Using CPU device\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:24,137 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:24,138 [RapidOCR] main.py:50: Using D:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\rapidocr\\models\\ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:24,196 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:24,200 [RapidOCR] device_config.py:50: Using CPU device\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:24,237 [RapidOCR] download_file.py:60: File exists and is valid: D:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
      "\u001b[32m[INFO] 2026-01-20 16:30:24,238 [RapidOCR] main.py:50: Using D:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.pth\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved intermediate file: data\\processed\\sample.md\n",
      "Result_doc: 1. Научные открытия и технологические прорывы\n",
      "\n",
      "В 2023 году учёные из ЦЕРНа подтвердили существование...\n"
     ]
    }
   ],
   "source": [
    "import src.document_loader as document_loader\n",
    "import config.config as cfg\n",
    "\n",
    "def test_load_document():\n",
    "    file_path = str(cfg.RAW_DATA_DIR / \"sample.pdf\")\n",
    "    result = document_loader.load_document(file_path)\n",
    "    print(f\"Result_doc: {result[0:100]}...\")  # Print first 100 characters for brevity\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_load_document()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f7c69",
   "metadata": {},
   "source": [
    "#### Чанкирование по кол-ву симовлов с перекрытием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d48ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл 'sample.md' успешно разбит.\n",
      "Количество чанков: 12\n",
      "Пример первого чанка:\n",
      "'1. Научные открытия и технологические прорывы\\n\\nВ 2023 году учёные из ЦЕРНа подтвердили существование'...\n"
     ]
    }
   ],
   "source": [
    "from src.chunker import chunk_text\n",
    "from config.config import PROCESSED_DATA_DIR\n",
    "\n",
    "file_path = PROCESSED_DATA_DIR / \"sample.md\"\n",
    "markdown_content = file_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "CHUNK_SIZE = 500 \n",
    "OVERLAP = 100\n",
    "file_name = file_path.name # Сохраняем имя для Qdrant\n",
    "\n",
    "chunks = chunk_text(markdown_content, chunk_size=CHUNK_SIZE, overlap=OVERLAP)\n",
    "\n",
    "print(f\"Файл '{file_name}' успешно разбит.\")\n",
    "print(f\"Количество чанков: {len(chunks)}\")\n",
    "print(f\"Пример первого чанка:\\n{repr(chunks[0][:100])}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ec59d",
   "metadata": {},
   "source": [
    "#### Сохранение векторизованных данных в Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb057789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генерация векторов для 12 чанков...\n",
      "Данные успешно загружены в коллекцию 'docs_collection'\n"
     ]
    }
   ],
   "source": [
    "from src.embedder import vectorize_and_upload\n",
    "\n",
    "q_client, embed_model = vectorize_and_upload(chunks, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384e948",
   "metadata": {},
   "source": [
    "### Модули Retrieval и Reranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424063d",
   "metadata": {},
   "source": [
    "#### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "756d415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 3 кандидатов через векторный поиск.\n"
     ]
    }
   ],
   "source": [
    "from src.retrieval import retrieve\n",
    "\n",
    "user_query = \"Скольки градусам может достичь потепление к 2050 году?\"\n",
    "candidates = retrieve(user_query, q_client, embed_model, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1db76377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-3 кандидата по запросу:\n",
      "1. {'text': 'аду МГЭИК (Межправительственной группы экспертов по изменению климата) за 2022 год, глобальная средняя температура уже на 1,15°C выше доиндустриального уровня. Если выбросы парниковых газов не будут радикально сокращены, к 2050 году потепление может достичь 2,7°C, что приведёт к катастрофическим последствиям: повышению уровня моря, экстремальным погодным явлениям и массовому вымиранию видов.\\n\\nОднако существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утвержд', 'score': 0.7725014185102526, 'metadata': {'source': 'sample.md', 'chunk_id': 5}}\n",
      "\n",
      "2. {'text': 'ко существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утверждают, что адаптация к изменениям климата может быть более эффективной стратегией, чем полный отказ от ископаемого топлива. Тем не менее, большинство научного сообщества поддерживает Парижское соглашение 2015 года, целью которого является удержание роста температуры ниже 2°C.\\n\\n## 4. Искусственный интеллект и этика\\n\\nС развитием больших языковых моделей (LLM), таких как GPT-4, Llama 3 и Claude 3, возн', 'score': 0.5040614626197637, 'metadata': {'source': 'sample.md', 'chunk_id': 6}}\n",
      "\n",
      "3. {'text': ' содержащих стереотипы, она может их воспроизводить.\\n\\nВ то же время ИИ активно применяется в медицине: алгоритмы DeepMind (подразделение Google) помогают диагностировать диабетическую ретинопатию и рак молочной железы с точностью, сопоставимой с экспертами-людьми.\\n\\n## 5. География и демография\\n\\nНаселение Земли достигло 8 миллиардов человек в ноябре 2022 года. По прогнозам ООН, пик будет достигнут около 2086 года - на уровне 10,4 миллиарда. При этом старение населения становится серьёзной проблем', 'score': 0.36018809576390565, 'metadata': {'source': 'sample.md', 'chunk_id': 8}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Топ-3 кандидата по запросу:\")\n",
    "for i, candidate in enumerate(candidates, start=1):\n",
    "    print(f\"{i}. {candidate}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e1950a",
   "metadata": {},
   "source": [
    "#### Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12638658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Переранжирование завершено. Выбрано топ-3 наиболее релевантных.\n",
      "\n",
      "--- Релевантный чанк №1 (Score: 8.6397) ---\n",
      "аду МГЭИК (Межправительственной группы экспертов по изменению климата) за 2022 год, глобальная средняя температура уже на 1,15°C выше доиндустриального уровня. Если выбросы парниковых газов не будут р...\n",
      "\n",
      "--- Релевантный чанк №2 (Score: 8.4987) ---\n",
      " содержащих стереотипы, она может их воспроизводить.\n",
      "\n",
      "В то же время ИИ активно применяется в медицине: алгоритмы DeepMind (подразделение Google) помогают диагностировать диабетическую ретинопатию и ра...\n",
      "\n",
      "--- Релевантный чанк №3 (Score: 7.9926) ---\n",
      "ко существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утверждают, что адаптация к изменениям климата может быть более эффективной стратегией, чем полный отказ от...\n"
     ]
    }
   ],
   "source": [
    "from src.reranker import rerank\n",
    "\n",
    "final_context = rerank(user_query, candidates, top_n=3)\n",
    "\n",
    "# Вывод результата\n",
    "for i, res in enumerate(final_context):\n",
    "    print(f\"\\n--- Релевантный чанк №{i+1} (Score: {res['rerank_score']:.4f}) ---\")\n",
    "    print(res[\"text\"][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20977c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'аду МГЭИК (Межправительственной группы экспертов по изменению климата) за 2022 год, глобальная средняя температура уже на 1,15°C выше доиндустриального уровня. Если выбросы парниковых газов не будут радикально сокращены, к 2050 году потепление может достичь 2,7°C, что приведёт к катастрофическим последствиям: повышению уровня моря, экстремальным погодным явлениям и массовому вымиранию видов.\\n\\nОднако существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утвержд'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_context[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f76b69",
   "metadata": {},
   "source": [
    "### Модуль Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddfdfcb",
   "metadata": {},
   "source": [
    "#### Генератор с использованием локальной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c02169b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Сгенерированный ответ ---\n",
      "Согласно предоставленному контексту, потепление может достичь уровня 2,7°C к 2050 году.\n"
     ]
    }
   ],
   "source": [
    "from src.generator import Generator\n",
    "\n",
    "generator = Generator()\n",
    "\n",
    "user_query = \"Скольки градусам может достичь потепление к 2050 году?\"\n",
    "response = generator.generate(user_query, final_context[0][\"text\"])\n",
    "\n",
    "print(\"\\n--- Сгенерированный ответ ---\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c196d20",
   "metadata": {},
   "source": [
    "Получение итогового списка контекста модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d4f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_context_text = []\n",
    "for i in range(len(final_context)):\n",
    "    final_context_text.append(final_context[i][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e9c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['аду МГЭИК (Межправительственной группы экспертов по изменению климата) за 2022 год, глобальная средняя температура уже на 1,15°C выше доиндустриального уровня. Если выбросы парниковых газов не будут радикально сокращены, к 2050 году потепление может достичь 2,7°C, что приведёт к катастрофическим последствиям: повышению уровня моря, экстремальным погодным явлениям и массовому вымиранию видов.\\n\\nОднако существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утвержд', ' содержащих стереотипы, она может их воспроизводить.\\n\\nВ то же время ИИ активно применяется в медицине: алгоритмы DeepMind (подразделение Google) помогают диагностировать диабетическую ретинопатию и рак молочной железы с точностью, сопоставимой с экспертами-людьми.\\n\\n## 5. География и демография\\n\\nНаселение Земли достигло 8 миллиардов человек в ноябре 2022 года. По прогнозам ООН, пик будет достигнут около 2086 года - на уровне 10,4 миллиарда. При этом старение населения становится серьёзной проблем', 'ко существуют и контраргументы: некоторые исследователи, такие как климатолог Бьорн Ломборг, утверждают, что адаптация к изменениям климата может быть более эффективной стратегией, чем полный отказ от ископаемого топлива. Тем не менее, большинство научного сообщества поддерживает Парижское соглашение 2015 года, целью которого является удержание роста температуры ниже 2°C.\\n\\n## 4. Искусственный интеллект и этика\\n\\nС развитием больших языковых моделей (LLM), таких как GPT-4, Llama 3 и Claude 3, возн']\n"
     ]
    }
   ],
   "source": [
    "print(final_context_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52a094",
   "metadata": {},
   "source": [
    "---\n",
    "### Evaluation (Ragas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe6c993",
   "metadata": {},
   "source": [
    "#### Rertieaval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6555469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5011d7a0",
   "metadata": {},
   "source": [
    "#### Genearator evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810dc005",
   "metadata": {},
   "source": [
    "##### - Faithfulness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748d3da",
   "metadata": {},
   "source": [
    "Faithfulness metrics — насколько ответ соответствует фактам из ретривнутых документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad80646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithfulness: 1.0\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation.faithfulness import getting_faithfulness_metric\n",
    "import asyncio\n",
    "\n",
    "faithfulness_metric = await getting_faithfulness_metric(\"gpt-oss:20b\", user_query, response, final_context_text)\n",
    "print(f\"Faithfulness: {faithfulness_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a692005",
   "metadata": {},
   "source": [
    "##### - Response Relevancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eefdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SentenceTransformer' object has no attribute 'embed_query'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m      5\u001b[39m embed_model = SentenceTransformer(\u001b[33m'\u001b[39m\u001b[33mparaphrase-multilingual-MiniLM-L12-v2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m resp_rel_metric = \u001b[38;5;28;01mawait\u001b[39;00m getting_resp_rel_metric(\u001b[33m\"\u001b[39m\u001b[33mgpt-oss:20b\u001b[39m\u001b[33m\"\u001b[39m, embed_model, user_query, response, final_context_text)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFaithfulness: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp_rel_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\LocalRAG\\src\\evaluation\\response_relevancy.py:22\u001b[39m, in \u001b[36mgetting_resp_rel_metric\u001b[39m\u001b[34m(judje_model, embeddings, user_input, response, retrieved_context)\u001b[39m\n\u001b[32m     15\u001b[39m sample = SingleTurnSample(\n\u001b[32m     16\u001b[39m         user_input=user_input,\n\u001b[32m     17\u001b[39m         response=response,\n\u001b[32m     18\u001b[39m         retrieved_contexts=retrieved_context\n\u001b[32m     19\u001b[39m     )\n\u001b[32m     21\u001b[39m scorer = ResponseRelevancy(llm=llm, embeddings=embeddings)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m scorer.single_turn_ascore(sample)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\ragas\\metrics\\base.py:488\u001b[39m, in \u001b[36mSingleTurnMetric.single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks, timeout)\u001b[39m\n\u001b[32m    486\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n\u001b[32m    487\u001b[39m         rm.on_chain_error(e)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    490\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\ragas\\metrics\\base.py:481\u001b[39m, in \u001b[36mSingleTurnMetric.single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks, timeout)\u001b[39m\n\u001b[32m    474\u001b[39m rm, group_cm = new_group(\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    476\u001b[39m     inputs=sample.to_dict(),\n\u001b[32m    477\u001b[39m     callbacks=callbacks,\n\u001b[32m    478\u001b[39m     metadata={\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: ChainType.METRIC},\n\u001b[32m    479\u001b[39m )\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m     score = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.wait_for(\n\u001b[32m    482\u001b[39m         \u001b[38;5;28mself\u001b[39m._single_turn_ascore(sample=sample, callbacks=group_cm),\n\u001b[32m    483\u001b[39m         timeout=timeout,\n\u001b[32m    484\u001b[39m     )\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    486\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m group_cm.ended:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:520\u001b[39m, in \u001b[36mwait_for\u001b[39m\u001b[34m(fut, timeout)\u001b[39m\n\u001b[32m    517\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m timeouts.timeout(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m fut\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py:135\u001b[39m, in \u001b[36mResponseRelevancy._single_turn_ascore\u001b[39m\u001b[34m(self, sample, callbacks)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_single_turn_ascore\u001b[39m(\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mself\u001b[39m, sample: SingleTurnSample, callbacks: Callbacks\n\u001b[32m    133\u001b[39m ) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m    134\u001b[39m     row = sample.to_dict()\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._ascore(row, callbacks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py:146\u001b[39m, in \u001b[36mResponseRelevancy._ascore\u001b[39m\u001b[34m(self, row, callbacks)\u001b[39m\n\u001b[32m    140\u001b[39m prompt_input = ResponseRelevanceInput(response=row[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    142\u001b[39m responses = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.question_generation.generate_multiple(\n\u001b[32m    143\u001b[39m     data=prompt_input, llm=\u001b[38;5;28mself\u001b[39m.llm, callbacks=callbacks, n=\u001b[38;5;28mself\u001b[39m.strictness\n\u001b[32m    144\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_calculate_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py:126\u001b[39m, in \u001b[36mResponseRelevancy._calculate_score\u001b[39m\u001b[34m(self, answers, row)\u001b[39m\n\u001b[32m    124\u001b[39m     score = np.nan\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     cosine_sim = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcalculate_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_questions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m     score = cosine_sim.mean() * \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m all_noncommittal)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py:100\u001b[39m, in \u001b[36mResponseRelevancy.calculate_similarity\u001b[39m\u001b[34m(self, question, generated_questions)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_similarity\u001b[39m(\u001b[38;5;28mself\u001b[39m, question: \u001b[38;5;28mstr\u001b[39m, generated_questions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, (\n\u001b[32m     98\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m requires embeddings to be set.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     99\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     question_vec = np.asarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m(question)).reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    101\u001b[39m     gen_question_vec = np.asarray(\n\u001b[32m    102\u001b[39m         \u001b[38;5;28mself\u001b[39m.embeddings.embed_documents(generated_questions)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    103\u001b[39m     ).reshape(\u001b[38;5;28mlen\u001b[39m(generated_questions), -\u001b[32m1\u001b[39m)\n\u001b[32m    104\u001b[39m     norm = np.linalg.norm(gen_question_vec, axis=\u001b[32m1\u001b[39m) * np.linalg.norm(\n\u001b[32m    105\u001b[39m         question_vec, axis=\u001b[32m1\u001b[39m\n\u001b[32m    106\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\LocalRAG\\.ven\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'SentenceTransformer' object has no attribute 'embed_query'"
     ]
    }
   ],
   "source": [
    "from src.evaluation.response_relevancy import getting_resp_rel_metric\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import asyncio\n",
    "\n",
    "# Пример вызова\n",
    "result = await getting_resp_rel_metric(\n",
    "    judje_model=\"gpt-oss:20b\",\n",
    "    embeddings_model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    user_input=user_query,\n",
    "    response=response,\n",
    "    retrieved_context=final_context_text\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
